{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/hkproj/pytorch-stable-diffusion.git\n!git clone https://huggingface.co/pt-sk/SDcheckpoint\n!git clone https://huggingface.co/pt-sk/CLIPTOKENIZER","metadata":{"execution":{"iopub.status.busy":"2024-05-31T16:50:36.264933Z","iopub.execute_input":"2024-05-31T16:50:36.265639Z","iopub.status.idle":"2024-05-31T16:53:55.113333Z","shell.execute_reply.started":"2024-05-31T16:50:36.265608Z","shell.execute_reply":"2024-05-31T16:53:55.111950Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'pytorch-stable-diffusion'...\nremote: Enumerating objects: 69, done.\u001b[K\nremote: Counting objects: 100% (33/33), done.\u001b[K\nremote: Compressing objects: 100% (19/19), done.\u001b[K\nremote: Total 69 (delta 21), reused 14 (delta 14), pack-reused 36\u001b[K\nUnpacking objects: 100% (69/69), 1.96 MiB | 6.59 MiB/s, done.\nCloning into 'SDcheckpoint'...\nremote: Enumerating objects: 7, done.\u001b[K\nremote: Counting objects: 100% (3/3), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 7 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\nUnpacking objects: 100% (7/7), 2.20 KiB | 2.20 MiB/s, done.\nEncountered 1 file(s) that may not have been copied correctly on Windows:\n\tv1-5-pruned-emaonly.ckpt\n\nSee: `git lfs help smudge` for more details.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom shutil import copyfile\nfiles = os.listdir(\"/kaggle/working/pytorch-stable-diffusion/sd\")\n\nfor file in files:\n    if file.endswith(\".py\"): \n        copyfile(src = f\"/kaggle/working/pytorch-stable-diffusion/sd/{file}\", dst = f\"/kaggle/working/{file}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-31T16:57:39.523662Z","iopub.execute_input":"2024-05-31T16:57:39.524070Z","iopub.status.idle":"2024-05-31T16:57:39.530992Z","shell.execute_reply.started":"2024-05-31T16:57:39.524027Z","shell.execute_reply":"2024-05-31T16:57:39.530182Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# necessary libraries\nimport math\nimport json\nimport pandas as pd\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.io import read_image\nfrom tqdm import tqdm\nfrom torch.optim import AdamW\nfrom torchvision import transforms\nfrom transformers import CLIPTokenizer\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\nfrom diffusion import Diffusion\nfrom model_loader import preload_models_from_standard_weights\nfrom ddpm import DDPMSampler\n# import torch_xla\n# import torch_xla.core.xla_model as xm","metadata":{"_uuid":"215c76f2-3a3a-4821-b7a5-db5e1b8ded49","_cell_guid":"2911c5f1-a8d3-4394-9baf-135c8dd7ccd8","collapsed":false,"id":"AldVDvOgcpbc","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-31T16:58:35.141295Z","iopub.execute_input":"2024-05-31T16:58:35.141668Z","iopub.status.idle":"2024-05-31T16:58:35.152159Z","shell.execute_reply.started":"2024-05-31T16:58:35.141640Z","shell.execute_reply":"2024-05-31T16:58:35.151362Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# CONSTANT VARIABLES\nBASE_PATH = '../input/coco-2017-dataset/coco2017'\nIMAGES = [\"train2017\", \"val2017\", \"test2017\"]\nIMAGE_SIZE = (512, 512)\nNUM_WORKERS = 4\nBATCH_SIZE = 2\n# device = xm.xla_device()","metadata":{"_uuid":"4ae2d32c-406a-4702-bc7f-bc269e47ef29","_cell_guid":"39055bc9-3647-4827-bc2d-dd3daa6df23e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-31T16:57:53.285045Z","iopub.execute_input":"2024-05-31T16:57:53.285434Z","iopub.status.idle":"2024-05-31T16:57:53.290038Z","shell.execute_reply.started":"2024-05-31T16:57:53.285409Z","shell.execute_reply":"2024-05-31T16:57:53.289096Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# using train2017\nwith open(f'{BASE_PATH}/annotations/captions_train2017.json', 'r') as f:\n    data = json.load(f)\n    data = data['annotations']\n\nimg_cap_pairs = []\n\nfor sample in data:\n    img_name = '%012d.jpg' % sample['image_id']\n    img_cap_pairs.append([img_name, sample['caption']])\n\ncaptions = pd.DataFrame(img_cap_pairs, columns=['image', 'caption'])\ncaptions['image'] = captions['image'].apply(\n    lambda x: f'{BASE_PATH}/train2017/{x}'\n)\ncaptions = captions.head(50000)\ncaptions.head()","metadata":{"_uuid":"c491e5ed-12f4-4af5-996e-a0b3e09614df","_cell_guid":"a0da1a80-4225-4e86-91ae-ceb6aa4b5f06","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-31T16:57:53.291322Z","iopub.execute_input":"2024-05-31T16:57:53.292159Z","iopub.status.idle":"2024-05-31T16:57:56.961899Z","shell.execute_reply.started":"2024-05-31T16:57:53.292114Z","shell.execute_reply":"2024-05-31T16:57:56.960993Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               image  \\\n0  ../input/coco-2017-dataset/coco2017/train2017/...   \n1  ../input/coco-2017-dataset/coco2017/train2017/...   \n2  ../input/coco-2017-dataset/coco2017/train2017/...   \n3  ../input/coco-2017-dataset/coco2017/train2017/...   \n4  ../input/coco-2017-dataset/coco2017/train2017/...   \n\n                                             caption  \n0  A bicycle replica with a clock as the front wh...  \n1  A room with blue walls and a white sink and door.  \n2  A car that seems to be parked illegally behind...  \n3  A large passenger airplane flying through the ...  \n4  There is a GOL plane taking off in a partly cl...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/coco-2017-dataset/coco2017/train2017/...</td>\n      <td>A bicycle replica with a clock as the front wh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/coco-2017-dataset/coco2017/train2017/...</td>\n      <td>A room with blue walls and a white sink and door.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/coco-2017-dataset/coco2017/train2017/...</td>\n      <td>A car that seems to be parked illegally behind...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/coco-2017-dataset/coco2017/train2017/...</td>\n      <td>A large passenger airplane flying through the ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/coco-2017-dataset/coco2017/train2017/...</td>\n      <td>There is a GOL plane taking off in a partly cl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# transformations for the images\ntransform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE, transforms.InterpolationMode.BICUBIC),\n    transforms.CenterCrop(IMAGE_SIZE),\n    transforms.ToTensor()\n])","metadata":{"_uuid":"e319dd9e-3585-4000-a67c-fae972f9c697","_cell_guid":"771f05f5-d152-4cf9-afba-ecaee5d2dbb0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-31T16:57:56.966506Z","iopub.execute_input":"2024-05-31T16:57:56.967214Z","iopub.status.idle":"2024-05-31T16:57:56.973219Z","shell.execute_reply.started":"2024-05-31T16:57:56.967178Z","shell.execute_reply":"2024-05-31T16:57:56.972188Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# creating a customimage dataset\nclass ImageCaptions_Dataset(Dataset):\n    def __init__(self, captions: pd.DataFrame, transforms):\n        self.dataframe = captions\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        image = self.dataframe.iloc[idx][\"image\"]\n        caption = self.dataframe.iloc[idx][\"caption\"]\n        \n        image = Image.open(image)\n        image = self.transforms(image)\n        \n        return image, caption\n\n# creating image captions dataset\nimage_captions_dataset = ImageCaptions_Dataset(captions, transform)\n\n# creating image captions dataloader\nimage_captions_dataloader = DataLoader(image_captions_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)","metadata":{"_uuid":"14b0d0a5-50c0-4ba4-96bc-21268ad82ec5","_cell_guid":"1d932564-fd42-431e-b644-dbfec8c78b47","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-31T16:57:56.974575Z","iopub.execute_input":"2024-05-31T16:57:56.974967Z","iopub.status.idle":"2024-05-31T16:57:56.988553Z","shell.execute_reply.started":"2024-05-31T16:57:56.974922Z","shell.execute_reply":"2024-05-31T16:57:56.987705Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# instantiating models\nmodels = preload_models_from_standard_weights(\"/kaggle/working/SDcheckpoint/v1-5-pruned-emaonly.ckpt\", \"cuda:1\")\nencoder = models[\"encoder\"]\ndecoder = models[\"decoder\"]\nclip = models[\"clip\"]\n\nmodel = Diffusion().to(\"cuda:0\")","metadata":{"execution":{"iopub.status.busy":"2024-05-31T16:57:56.989753Z","iopub.execute_input":"2024-05-31T16:57:56.990073Z","iopub.status.idle":"2024-05-31T16:58:23.668572Z","shell.execute_reply.started":"2024-05-31T16:57:56.990032Z","shell.execute_reply":"2024-05-31T16:58:23.667699Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"a, b = next(iter(image_captions_dataloader))","metadata":{"execution":{"iopub.status.busy":"2024-05-31T16:58:23.669730Z","iopub.execute_input":"2024-05-31T16:58:23.670083Z","iopub.status.idle":"2024-05-31T16:58:24.102634Z","shell.execute_reply.started":"2024-05-31T16:58:23.670050Z","shell.execute_reply":"2024-05-31T16:58:24.101577Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = CLIPTokenizer(\"/kaggle/working/CLIPTOKENIZER/vocab.json\", merges_file=\"/kaggle/working/CLIPTOKENIZER/merges.txt\")","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:04:36.575514Z","iopub.execute_input":"2024-05-31T17:04:36.576000Z","iopub.status.idle":"2024-05-31T17:04:36.672379Z","shell.execute_reply.started":"2024-05-31T17:04:36.575959Z","shell.execute_reply":"2024-05-31T17:04:36.671559Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"text = tokenizer.batch_encode_plus(\n                b, padding=\"max_length\", max_length=77\n            ).input_ids","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:07:21.666006Z","iopub.execute_input":"2024-05-31T17:07:21.666844Z","iopub.status.idle":"2024-05-31T17:07:21.672687Z","shell.execute_reply.started":"2024-05-31T17:07:21.666810Z","shell.execute_reply":"2024-05-31T17:07:21.671658Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}